# Default Spark configuration.
# Properties set directly on the SparkConf take the highest precedence, 
# then those through --conf flags or --properties-file passed to spark-submit or spark-shell, 
# then options in the spark-defaults.conf file (this file).
spark.master                     spark://spark-master:7077
spark.hadoop.fs.defaultFS        hdfs://hdfs-namenode:8020
spark.sql.warehouse.dir          hdfs:///user/hive/warehouse

# Delta Lake dependencies (compatible with Spark 3.5.x)
spark.jars.packages              io.delta:delta-spark_2.12:3.1.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1

# Event logging for History Server
spark.eventLog.enabled           true
spark.eventLog.dir               hdfs://hdfs-namenode:8020/spark-logs
spark.history.fs.logDirectory    hdfs://hdfs-namenode:8020/spark-logs